{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch an OpenSearch DocumentStore\n",
    "\n",
    "Below, we create an `OpenSearchDocumentStore` which by default connects to an OpenSearch service.\n",
    "\n",
    "Chage the host, port, username and password below to run the following indexing pipeline on your own OpenSearch service in AWS.\n",
    "\n",
    "If you would like to use an OpenSearch servide on AWS, first follow the [instructions](/README.md#option-1-opensearch-service-on-aws) on how to deploy an OpenSearch instance with the provided `opensearch-index.yaml` CloudFormation template.\n",
    "\n",
    "Another option is to simply launch an OpenSearch instance locally (for which you need docker). If you would prefer to do this, first run:\n",
    "\n",
    "```python\n",
    "from haystack.utils import launch_opensearch\n",
    "\n",
    "launch_opensearch()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import OpenSearchDocumentStore\n",
    "\n",
    "doc_store = OpenSearchDocumentStore(host='your_opensearch_host', port=443, username= \"admin\", password=\"admin\", embedding_dim=384)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Pipeline to write Documents to OpenSearch\n",
    "\n",
    "An indexing pipeline allows you to prepare your files and write them to a database that you would like to use with your NLP application. In this example, we're using OpenSearch as our vector database. We define an indexing pipeline that converts JSON files (that have been crawled from the OpenSearch documentation and website), and creates embeddings for them using the `sentence-transformers/all-MiniLM-L12-v2` model, which is a very small embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import JsonConverter\n",
    "\n",
    "converter = JsonConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "preprocessor = PreProcessor (\n",
    "        clean_empty_lines=True, \n",
    "        split_by='word',\n",
    "        split_respect_sentence_boundary=True,\n",
    "        split_length=80,\n",
    "        split_overlap=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import EmbeddingRetriever\n",
    "\n",
    "retriever = EmbeddingRetriever(document_store=doc_store, embedding_model=\"sentence-transformers/all-MiniLM-L12-v2\", devices=[\"mps\"], top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_node(component=converter, name=\"Converter\", inputs=[\"File\"])\n",
    "indexing_pipeline.add_node(component=preprocessor, name=\"Preprocessor\", inputs=[\"Converter\"])\n",
    "indexing_pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Preprocessor\"])\n",
    "indexing_pipeline.add_node(component=doc_store, name=\"DocumentStore\", inputs=[\"Retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_pipeline.run(file_paths=[\"data/opensearch-documentation-2.7.json\", \"data/opensearch-website.json\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemeker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
